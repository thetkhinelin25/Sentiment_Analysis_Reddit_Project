{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9187aa4f-2412-493f-9891-5c8de0387003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/Assignment_project/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-macosx_14_0_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/Assignment_project/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-macosx_14_0_x86_64.whl (25.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.5/25.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af557b4e-65ad-4970-8c5f-3709e4a0aa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after seeing this uvjx3kwoehw video seems anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you killed karma</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was voluntary sale not forced anyone then wha...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weird see this because was just talking about...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modi undoubtedly the worst thing that has happ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category Sentiment_Label\n",
       "0  after seeing this uvjx3kwoehw video seems anyt...         0         Neutral\n",
       "1                                  you killed karma         -1        Negative\n",
       "2   was voluntary sale not forced anyone then wha...         1        Positive\n",
       "3   weird see this because was just talking about...         1        Positive\n",
       "4  modi undoubtedly the worst thing that has happ...        -1        Negative"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Update the file path to include the full path to the dataset file\n",
    "df = pd.read_csv(\"Reddit_Data.csv\")\n",
    "\n",
    "# Remove rows with NaN or None in the 'clean_comment' column\n",
    "df = df[df['clean_comment'].notna()]\n",
    "\n",
    "# Reduce the dataset to 300 samples\n",
    "df = df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Map category values to sentiment labels\n",
    "sentiment_map = {-1: \"Negative\", 0: \"Neutral\", 1: \"Positive\"}\n",
    "df['Sentiment_Label'] = df['category'].map(sentiment_map)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64dff91-2202-48b4-83a4-1fc4a2d26c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Assignment_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model  Accuracy\n",
      "0     VADER     0.642\n",
      "1  TextBlob     0.818\n",
      "2      BERT     0.354\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize sentiment analysis models\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "bert = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Define VADER prediction function with standard ranges\n",
    "def predict_vader(text):\n",
    "    compound = vader.polarity_scores(text)['compound']\n",
    "    if compound > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Define TextBlob prediction function with standard ranges\n",
    "def predict_textblob(text):\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    if polarity > 0.1:  # Updated threshold for positive\n",
    "        return \"Positive\"\n",
    "    elif polarity < -0.1:  # Updated threshold for negative\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Define BERT prediction function with standard ranges\n",
    "def predict_bert(text):\n",
    "    result = bert(text[:512])[0]  # Limit text to 512 tokens\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "\n",
    "    if score < 0.6:  # Low confidence means Neutral\n",
    "        return \"Neutral\"\n",
    "    elif label == \"POSITIVE\":\n",
    "        return \"Positive\"\n",
    "    elif label == \"NEGATIVE\":\n",
    "        return \"Negative\"\n",
    "\n",
    "# Apply sentiment analysis models to the dataset\n",
    "df['VADER_Predicted'] = df['clean_comment'].apply(predict_vader)\n",
    "df['TextBlob_Predicted'] = df['clean_comment'].apply(predict_textblob)\n",
    "df['BERT_Predicted'] = df['clean_comment'].apply(predict_bert)\n",
    "\n",
    "# Evaluate accuracy for each model\n",
    "def calculate_accuracy(predicted_col, true_col):\n",
    "    return (df[predicted_col] == df[true_col]).mean()\n",
    "\n",
    "vader_accuracy = calculate_accuracy('VADER_Predicted', 'Sentiment_Label')\n",
    "textblob_accuracy = calculate_accuracy('TextBlob_Predicted', 'Sentiment_Label')\n",
    "bert_accuracy = calculate_accuracy('BERT_Predicted', 'Sentiment_Label')\n",
    "\n",
    "# Create a dictionary of model accuracies\n",
    "accuracy_data = {\n",
    "    'Model': ['VADER', 'TextBlob', 'BERT'],\n",
    "    'Accuracy': [vader_accuracy, textblob_accuracy, bert_accuracy]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "accuracy_df = pd.DataFrame(accuracy_data)\n",
    "\n",
    "# Display the accuracy DataFrame\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45cb5fc-76c4-4640-a704-cb096d8d874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VADER Classification Report (Cleaned):\n",
      "          precision    recall  f1-score\n",
      "Negative   0.447811  0.627358  0.522593\n",
      "Neutral    0.765957  0.591781  0.667697\n",
      "Positive   0.695962  0.692671  0.694313\n",
      "accuracy   0.642000  0.642000  0.642000\n",
      "\n",
      "VADER Confusion Matrix:\n",
      "[[293  38  92]\n",
      " [ 77 216  72]\n",
      " [ 51  28 133]]\n",
      "\n",
      "TextBlob Classification Report (Cleaned):\n",
      "          precision    recall  f1-score\n",
      "Negative   1.000000  0.599057  0.749263\n",
      "Neutral    0.667276  1.000000  0.800439\n",
      "Positive   1.000000  0.770686  0.870494\n",
      "accuracy   0.818000  0.818000  0.818000\n",
      "\n",
      "TextBlob Confusion Matrix:\n",
      "[[326  97   0]\n",
      " [  0 365   0]\n",
      " [  0  85 127]]\n",
      "\n",
      "BERT Classification Report (Cleaned):\n",
      "          precision    recall  f1-score\n",
      "Negative   0.275148  0.877358  0.418919\n",
      "Neutral    0.588235  0.027397  0.052356\n",
      "Positive   0.514658  0.373522  0.432877\n",
      "accuracy   0.354000  0.354000  0.354000\n",
      "\n",
      "BERT Confusion Matrix:\n",
      "[[158   5 260]\n",
      " [125  10 230]\n",
      " [ 24   2 186]]\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize sentiment analysis models\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "bert = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Define VADER prediction function with standard ranges\n",
    "def predict_vader(text):\n",
    "    compound = vader.polarity_scores(text)['compound']\n",
    "    if compound > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Define TextBlob prediction function with standard ranges\n",
    "def predict_textblob(text):\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    if polarity > 0.1:  # Updated threshold for positive\n",
    "        return \"Positive\"\n",
    "    elif polarity < -0.1:  # Updated threshold for negative\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Define BERT prediction function with standard ranges\n",
    "def predict_bert(text):\n",
    "    result = bert(text[:512])[0]  # Limit text to 512 tokens\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "\n",
    "    if score < 0.6:  # Low confidence means Neutral\n",
    "        return \"Neutral\"\n",
    "    elif label == \"POSITIVE\":\n",
    "        return \"Positive\"\n",
    "    elif label == \"NEGATIVE\":\n",
    "        return \"Negative\"\n",
    "\n",
    "# Apply sentiment analysis models to the dataset\n",
    "df['VADER_Predicted'] = df['clean_comment'].apply(predict_vader)\n",
    "df['TextBlob_Predicted'] = df['clean_comment'].apply(predict_textblob)\n",
    "df['BERT_Predicted'] = df['clean_comment'].apply(predict_bert)\n",
    "\n",
    "# Define function to generate metrics and confusion matrix\n",
    "def evaluate_model(predicted_col, true_col):\n",
    "    true_labels = df[true_col]\n",
    "    predicted_labels = df[predicted_col]\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=[\"Positive\", \"Neutral\", \"Negative\"])\n",
    "\n",
    "    return report, cm\n",
    "\n",
    "# Function to clean classification report for display\n",
    "def clean_classification_report(report):\n",
    "    # Convert report to DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    # Drop 'support' column and unwanted rows\n",
    "    report_df = report_df.drop(columns='support', errors='ignore')\n",
    "    report_df = report_df.drop(index=['macro avg', 'weighted avg'], errors='ignore')\n",
    "    return report_df\n",
    "\n",
    "# Evaluate each model\n",
    "vader_report, vader_cm = evaluate_model('VADER_Predicted', 'Sentiment_Label')\n",
    "textblob_report, textblob_cm = evaluate_model('TextBlob_Predicted', 'Sentiment_Label')\n",
    "bert_report, bert_cm = evaluate_model('BERT_Predicted', 'Sentiment_Label')\n",
    "\n",
    "# Clean and display VADER report\n",
    "vader_cleaned_report = clean_classification_report(vader_report)\n",
    "print(\"\\nVADER Classification Report (Cleaned):\")\n",
    "print(vader_cleaned_report)\n",
    "print(\"\\nVADER Confusion Matrix:\")\n",
    "print(vader_cm)\n",
    "\n",
    "# Clean and display TextBlob report\n",
    "textblob_cleaned_report = clean_classification_report(textblob_report)\n",
    "print(\"\\nTextBlob Classification Report (Cleaned):\")\n",
    "print(textblob_cleaned_report)\n",
    "print(\"\\nTextBlob Confusion Matrix:\")\n",
    "print(textblob_cm)\n",
    "\n",
    "# Clean and display BERT report\n",
    "bert_cleaned_report = clean_classification_report(bert_report)\n",
    "print(\"\\nBERT Classification Report (Cleaned):\")\n",
    "print(bert_cleaned_report)\n",
    "print(\"\\nBERT Confusion Matrix:\")\n",
    "print(bert_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090910de-4485-4745-a8a6-6c47bdb3e9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
